{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19271a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using : cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch , torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import optuna\n",
    "import os\n",
    "import glob\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('You are using :',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca4f75",
   "metadata": {},
   "source": [
    "Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "# Function for Wavelet Decomposition\n",
    "#------------------------------------\n",
    "\n",
    "def wavelet_decomposition(image, mean=None, std=None):\n",
    "    image = np.array(image)/255.0\n",
    "    channels = [image[..., i] for i in range(3)]\n",
    "    LLs, LHs, HLs, HHs = [], [], [], []\n",
    "    \n",
    "    for ch in channels:\n",
    "        coeffs2 = pywt.swt2(ch, 'db1', level=1)\n",
    "        LL, (LH, HL, HH) = coeffs2[0]\n",
    "        LLs.append(LL); LHs.append(LH); HLs.append(HL); HHs.append(HH)\n",
    "    \n",
    "    Image_rgb = (image - mean)/std\n",
    "    LL_rgb = (np.stack(LLs, axis=-1)-mean)/std\n",
    "    LH_rgb = (np.stack(LHs, axis=-1)-mean)/std\n",
    "    HL_rgb = (np.stack(HLs, axis=-1)-mean)/std\n",
    "    HH_rgb = (np.stack(HHs, axis=-1)-mean)/std\n",
    "\n",
    "    Image_concat = np.concatenate([Image_rgb, LL_rgb, LH_rgb, HL_rgb, HH_rgb], axis=2)\n",
    "    Image_tensor = torch.from_numpy(Image_concat).float().permute(2, 0, 1)\n",
    "    return Image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2ab2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Class to load the images into Dataset\n",
    "#--------------------------------------\n",
    "\n",
    "class Load_Dataset(Dataset):\n",
    "    def __init__(self, data_path, transform = None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(self.data_path))\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            for path in glob.glob(os.path.join(self.data_path, cls) + '/*'):\n",
    "                self.samples.append(path)\n",
    "                self.targets.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.samples[idx]\n",
    "        target = self.targets[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return (image, torch.tensor(target, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f2ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# Class for decomposing the images of the dataset\n",
    "#------------------------------------------------\n",
    "\n",
    "class Transform_Dataset(Dataset):\n",
    "    def __init__(self, data_images, mean = None, std= None):  \n",
    "        if mean is None or std is None:\n",
    "            raise ValueError(\"Provide the mean and std\")\n",
    "        self.data_images = data_images\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data_images[idx][0]\n",
    "        target = self.data_images[idx][1]\n",
    "        image = image.resize((150,150))\n",
    "        image_tensor = wavelet_decomposition(image, self.mean, self.std)\n",
    "        return (image_tensor, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba527c33",
   "metadata": {},
   "source": [
    "Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d413aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Conv, self).__init__()\n",
    "        if stride>1:\n",
    "            padding= kernel_size//stride\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size,\n",
    "                                    stride=stride, padding=padding, groups=in_channels)\n",
    "        \n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e3b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, kernel):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=in_channels, out_channels=hidden_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=hidden_channels,out_channels=hidden_channels, kernel_size=kernel, padding='same'),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=hidden_channels, out_channels=in_channels, kernel_size=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.convolution(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e37829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=channels, out_channels=1, kernel_size=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=1,out_channels=1, kernel_size=kernel, padding='same'),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            Conv(in_channels=1, out_channels=channels, kernel_size=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.convolution(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c859cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Block, self).__init__()\n",
    "        self.str=stride\n",
    "        self.conv = Conv(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.batchNorm = nn.BatchNorm2d(out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.batchNorm(self.conv(x)), negative_slope=0.01)\n",
    "        if self.str == 1:\n",
    "            out = self.maxpool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42860da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------\n",
    "# Class of the custom model\n",
    "#--------------------------\n",
    "\n",
    "class EMU_FireNet(nn.Module):\n",
    "    def __init__(self, depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                 depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                 kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize, droupout=0.2):\n",
    "        super(EMU_FireNet, self).__init__()\n",
    "        \n",
    "        self.branch1 = Block(3, depth1, kernel1, stride = stride, padding = padding1)\n",
    "        self.branch2 = Block(3, depth2, kernel1, stride = stride, padding = padding1)\n",
    "        #self.branch3 = Block(9, depth3, kernel1, stride = stride, padding = padding1)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            Conv(depth1+depth2+depth3, depth4, kernel2, padding=padding2),\n",
    "            nn.BatchNorm2d(depth4),\n",
    "            nn.ReLU(),\n",
    "            Conv(depth4, depth5, kernel2, stride=1),\n",
    "            ResidualBlock(depth5, kernel2),\n",
    "            nn.BatchNorm2d(depth5),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            Conv(depth5, depth6, kernel3,stride=2),\n",
    "            InvertedResidualBlock(depth6, hidden_depth, kernel3),\n",
    "            nn.BatchNorm2d(depth6),\n",
    "            nn.ReLU(),\n",
    "            Conv(depth6, depth7, kernel3, padding=padding2),\n",
    "            ResidualBlock(depth7, kernel3),\n",
    "            nn.BatchNorm2d(depth7),\n",
    "            nn.ReLU(),\n",
    "            Conv(depth7, depth8, kernel3, stride=2),\n",
    "            ResidualBlock(depth8, kernel3),\n",
    "            nn.BatchNorm2d(depth8),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            Conv(depth8, depth8, kernel3, padding= padding2),\n",
    "            nn.BatchNorm2d(depth8),\n",
    "            nn.ReLU(),\n",
    "            Conv(depth8, depth9, kernel3, stride=2),\n",
    "            InvertedResidualBlock(depth9, hidden_depth2, kernel3),\n",
    "            nn.BatchNorm2d(depth9),\n",
    "            nn.ReLU(),\n",
    "            Conv(depth9, depth10, kernel2, stride=2),\n",
    "            nn.BatchNorm2d(depth10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.averagepool = nn.AvgPool2d(2,2)\n",
    "        self.adaptivepooling = nn.AdaptiveAvgPool2d((avgsize,avgsize))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=droupout),\n",
    "            nn.Linear(avgsize*avgsize*depth10, 2),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.branch1(x[:,:3,:,:])\n",
    "        out_2 = self.branch2(x[:,3:6,:,:])\n",
    "        out_3 = self.averagepool(x[:,6:,:,:])\n",
    "        \n",
    "        out = torch.cat([out_1, out_2, out_3], dim=1)\n",
    "        out = self.features(out)\n",
    "        out = self.adaptivepooling(out)\n",
    "        out = out.view(x.size(0),-1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15785fce",
   "metadata": {},
   "source": [
    "Fine tune the hyperparameters using BO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9eccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------\n",
    "# Define objective function using optuna\n",
    "#---------------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "    # define the search space\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-2, log=True)\n",
    "    # opt= trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
    "    depth1 = trial.suggest_categorical(\"depth1\", [8, 16,32,64 ])\n",
    "    depth2 = trial.suggest_categorical(\"depth2\", [1, 2 ])\n",
    "    depth3 = 9\n",
    "    depth4 = trial.suggest_categorical(\"depth4\", [16, 32, 64])\n",
    "    depth5 = trial.suggest_categorical(\"depth5\", [24, 32, 64])\n",
    "    depth6 = trial.suggest_categorical(\"depth6\", [32, 64, 128])\n",
    "    depth7 = trial.suggest_categorical(\"depth7\", [64, 128, 256])\n",
    "    depth8 = trial.suggest_categorical(\"depth8\", [128, 224, 512])\n",
    "    depth9 = trial.suggest_categorical(\"depth9\", [224, 256, 512])\n",
    "    depth10 = trial.suggest_categorical(\"depth10\", [256, 512])\n",
    "    kernel1 = trial.suggest_categorical(\"kernel1\", [5, 7, 11])\n",
    "    kernel2 = trial.suggest_categorical(\"kernel2\", [3, 5])\n",
    "    kernel3 = 3\n",
    "    avgsize = 1\n",
    "    dropout = 0.2 \n",
    "    hidden_depth = 128\n",
    "    hidden_depth2 = 512\n",
    "    stride = 2\n",
    "    padding1 = 5\n",
    "    padding2 = 0\n",
    "    \n",
    "    # data Loader\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle=False)\n",
    "    \n",
    "    # model initiliaztion\n",
    "    model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize,dropout)\n",
    "    model.to(device)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    # optimizer ssearchh space\n",
    "    # if opt == 'Adam':\n",
    "    #     optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "    # elif opt == 'SGD':\n",
    "    #     optimizer = optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "    # else:\n",
    "    #     optimizer = optim.RMSprop(model.parameters(), lr= learning_rate, weight_decay=0.0005)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr= learning_rate, weight_decay= 0.00045)\n",
    "    \n",
    "    \n",
    "    # Model train\n",
    "    model.train()\n",
    "    for epoch in range(5):      # 10 is the upper limit of epochs\n",
    "        for inputs, targets in tqdm(train_loader, desc=f'Trainin Loop {epoch+1}', leave= False):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # model evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0201368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sc\\AppData\\Local\\Temp\\ipykernel_6768\\1131860725.py:1: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  study_model = optuna.create_study(direction = 'maximize', sampler= optuna.samplers.GPSampler())\n",
      "[I 2025-11-13 08:22:14,529] A new study created in memory with name: no-name-d0770af1-c39f-479d-a177-0545a2e5c1ba\n",
      "[I 2025-11-13 09:08:13,844] Trial 0 finished with value: 0.520619731146047 and parameters: {'batch_size': 128, 'learning_rate': 4.793979231294992e-07, 'depth1': 32, 'depth2': 2, 'depth4': 32, 'depth5': 24, 'depth6': 64, 'depth7': 256, 'depth8': 128, 'depth9': 256, 'depth10': 256, 'kernel1': 11, 'kernel2': 3}. Best is trial 0 with value: 0.520619731146047.\n",
      "[I 2025-11-13 09:54:57,070] Trial 1 finished with value: 0.949419002050581 and parameters: {'batch_size': 256, 'learning_rate': 0.0029153714239884636, 'depth1': 32, 'depth2': 1, 'depth4': 16, 'depth5': 64, 'depth6': 128, 'depth7': 256, 'depth8': 224, 'depth9': 224, 'depth10': 512, 'kernel1': 7, 'kernel2': 5}. Best is trial 1 with value: 0.949419002050581.\n",
      "[I 2025-11-13 10:41:28,205] Trial 2 finished with value: 0.9774436090225563 and parameters: {'batch_size': 32, 'learning_rate': 0.0004364761238612481, 'depth1': 8, 'depth2': 2, 'depth4': 64, 'depth5': 24, 'depth6': 64, 'depth7': 64, 'depth8': 512, 'depth9': 256, 'depth10': 256, 'kernel1': 5, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 11:25:15,864] Trial 3 finished with value: 0.5611756664388243 and parameters: {'batch_size': 64, 'learning_rate': 5.481368116573751e-08, 'depth1': 16, 'depth2': 2, 'depth4': 32, 'depth5': 64, 'depth6': 128, 'depth7': 64, 'depth8': 512, 'depth9': 256, 'depth10': 256, 'kernel1': 7, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 12:12:46,631] Trial 4 finished with value: 0.5156071998177262 and parameters: {'batch_size': 256, 'learning_rate': 1.928898867117057e-08, 'depth1': 8, 'depth2': 2, 'depth4': 32, 'depth5': 32, 'depth6': 64, 'depth7': 256, 'depth8': 224, 'depth9': 224, 'depth10': 512, 'kernel1': 11, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 13:00:35,630] Trial 5 finished with value: 0.9735702893597631 and parameters: {'batch_size': 32, 'learning_rate': 0.0011964184178357806, 'depth1': 32, 'depth2': 1, 'depth4': 64, 'depth5': 64, 'depth6': 128, 'depth7': 64, 'depth8': 224, 'depth9': 512, 'depth10': 512, 'kernel1': 7, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 13:47:51,676] Trial 6 finished with value: 0.9355206197311461 and parameters: {'batch_size': 64, 'learning_rate': 5.217001918670848e-05, 'depth1': 16, 'depth2': 2, 'depth4': 32, 'depth5': 32, 'depth6': 64, 'depth7': 256, 'depth8': 512, 'depth9': 224, 'depth10': 256, 'kernel1': 11, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 14:32:57,762] Trial 7 finished with value: 0.860788334472545 and parameters: {'batch_size': 64, 'learning_rate': 2.6504681974107208e-06, 'depth1': 32, 'depth2': 1, 'depth4': 16, 'depth5': 64, 'depth6': 64, 'depth7': 256, 'depth8': 512, 'depth9': 256, 'depth10': 512, 'kernel1': 11, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 15:20:48,108] Trial 8 finished with value: 0.9644565960355435 and parameters: {'batch_size': 32, 'learning_rate': 0.003342022594506443, 'depth1': 64, 'depth2': 2, 'depth4': 32, 'depth5': 64, 'depth6': 128, 'depth7': 128, 'depth8': 512, 'depth9': 512, 'depth10': 512, 'kernel1': 5, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 16:08:19,610] Trial 9 finished with value: 0.8785600364547733 and parameters: {'batch_size': 64, 'learning_rate': 5.644612769581823e-06, 'depth1': 8, 'depth2': 1, 'depth4': 16, 'depth5': 24, 'depth6': 64, 'depth7': 128, 'depth8': 512, 'depth9': 256, 'depth10': 256, 'kernel1': 7, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 16:56:17,065] Trial 10 finished with value: 0.7953975848712691 and parameters: {'batch_size': 32, 'learning_rate': 0.01, 'depth1': 32, 'depth2': 1, 'depth4': 64, 'depth5': 64, 'depth6': 128, 'depth7': 64, 'depth8': 224, 'depth9': 512, 'depth10': 512, 'kernel1': 7, 'kernel2': 5}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 17:44:15,095] Trial 11 finished with value: 0.9510138983823194 and parameters: {'batch_size': 32, 'learning_rate': 0.01, 'depth1': 64, 'depth2': 2, 'depth4': 64, 'depth5': 64, 'depth6': 128, 'depth7': 128, 'depth8': 512, 'depth9': 512, 'depth10': 512, 'kernel1': 5, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 18:32:13,153] Trial 12 finished with value: 0.9605832763727501 and parameters: {'batch_size': 32, 'learning_rate': 0.004348899083957304, 'depth1': 32, 'depth2': 1, 'depth4': 64, 'depth5': 64, 'depth6': 128, 'depth7': 128, 'depth8': 224, 'depth9': 512, 'depth10': 512, 'kernel1': 7, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 19:19:12,563] Trial 13 finished with value: 0.9138755980861244 and parameters: {'batch_size': 32, 'learning_rate': 0.01, 'depth1': 32, 'depth2': 1, 'depth4': 64, 'depth5': 64, 'depth6': 128, 'depth7': 64, 'depth8': 224, 'depth9': 512, 'depth10': 512, 'kernel1': 5, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n",
      "[I 2025-11-13 20:07:05,893] Trial 14 finished with value: 0.9325586694007747 and parameters: {'batch_size': 32, 'learning_rate': 0.01, 'depth1': 64, 'depth2': 1, 'depth4': 32, 'depth5': 64, 'depth6': 128, 'depth7': 128, 'depth8': 512, 'depth9': 512, 'depth10': 512, 'kernel1': 7, 'kernel2': 3}. Best is trial 2 with value: 0.9774436090225563.\n"
     ]
    }
   ],
   "source": [
    "study_model = optuna.create_study(direction = 'maximize', sampler= optuna.samplers.GPSampler())\n",
    "study_model.optimize(objective, n_trials= 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7276b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters : {'batch_size': 32, 'learning_rate': 0.0004364761238612481, 'depth1': 8, 'depth2': 2, 'depth4': 64, 'depth5': 24, 'depth6': 64, 'depth7': 64, 'depth8': 512, 'depth9': 256, 'depth10': 256, 'kernel1': 5, 'kernel2': 5}\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters :', study_model.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52007126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 75, 75]             150\n",
      "            Conv2d-2           [-1, 32, 75, 75]             128\n",
      "              Conv-3           [-1, 32, 75, 75]               0\n",
      "       BatchNorm2d-4           [-1, 32, 75, 75]              64\n",
      "             Block-5           [-1, 32, 75, 75]               0\n",
      "            Conv2d-6            [-1, 3, 75, 75]             150\n",
      "            Conv2d-7            [-1, 1, 75, 75]               4\n",
      "              Conv-8            [-1, 1, 75, 75]               0\n",
      "       BatchNorm2d-9            [-1, 1, 75, 75]               2\n",
      "            Block-10            [-1, 1, 75, 75]               0\n",
      "        AvgPool2d-11            [-1, 9, 75, 75]               0\n",
      "           Conv2d-12           [-1, 42, 73, 73]             420\n",
      "           Conv2d-13           [-1, 64, 73, 73]           2,752\n",
      "             Conv-14           [-1, 64, 73, 73]               0\n",
      "      BatchNorm2d-15           [-1, 64, 73, 73]             128\n",
      "             ReLU-16           [-1, 64, 73, 73]               0\n",
      "           Conv2d-17           [-1, 64, 71, 71]             640\n",
      "           Conv2d-18           [-1, 64, 71, 71]           4,160\n",
      "             Conv-19           [-1, 64, 71, 71]               0\n",
      "      BatchNorm2d-20           [-1, 64, 71, 71]             128\n",
      "             ReLU-21           [-1, 64, 71, 71]               0\n",
      "           Conv2d-22           [-1, 64, 71, 71]             128\n",
      "           Conv2d-23            [-1, 1, 71, 71]              65\n",
      "             Conv-24            [-1, 1, 71, 71]               0\n",
      "      BatchNorm2d-25            [-1, 1, 71, 71]               2\n",
      "             ReLU-26            [-1, 1, 71, 71]               0\n",
      "           Conv2d-27            [-1, 1, 71, 71]              10\n",
      "           Conv2d-28            [-1, 1, 71, 71]               2\n",
      "             Conv-29            [-1, 1, 71, 71]               0\n",
      "      BatchNorm2d-30            [-1, 1, 71, 71]               2\n",
      "             ReLU-31            [-1, 1, 71, 71]               0\n",
      "           Conv2d-32            [-1, 1, 71, 71]               2\n",
      "           Conv2d-33           [-1, 64, 71, 71]             128\n",
      "             Conv-34           [-1, 64, 71, 71]               0\n",
      "    ResidualBlock-35           [-1, 64, 71, 71]               0\n",
      "      BatchNorm2d-36           [-1, 64, 71, 71]             128\n",
      "             ReLU-37           [-1, 64, 71, 71]               0\n",
      "           Conv2d-38           [-1, 64, 36, 36]             640\n",
      "           Conv2d-39          [-1, 128, 36, 36]           8,320\n",
      "             Conv-40          [-1, 128, 36, 36]               0\n",
      "      BatchNorm2d-41          [-1, 128, 36, 36]             256\n",
      "             ReLU-42          [-1, 128, 36, 36]               0\n",
      "           Conv2d-43          [-1, 128, 36, 36]             256\n",
      "           Conv2d-44          [-1, 128, 36, 36]          16,512\n",
      "             Conv-45          [-1, 128, 36, 36]               0\n",
      "      BatchNorm2d-46          [-1, 128, 36, 36]             256\n",
      "             ReLU-47          [-1, 128, 36, 36]               0\n",
      "           Conv2d-48          [-1, 128, 36, 36]           1,280\n",
      "           Conv2d-49          [-1, 128, 36, 36]          16,512\n",
      "             Conv-50          [-1, 128, 36, 36]               0\n",
      "      BatchNorm2d-51          [-1, 128, 36, 36]             256\n",
      "             ReLU-52          [-1, 128, 36, 36]               0\n",
      "           Conv2d-53          [-1, 128, 36, 36]             256\n",
      "           Conv2d-54          [-1, 128, 36, 36]          16,512\n",
      "             Conv-55          [-1, 128, 36, 36]               0\n",
      "InvertedResidualBlock-56          [-1, 128, 36, 36]               0\n",
      "      BatchNorm2d-57          [-1, 128, 36, 36]             256\n",
      "             ReLU-58          [-1, 128, 36, 36]               0\n",
      "           Conv2d-59          [-1, 128, 34, 34]           1,280\n",
      "           Conv2d-60           [-1, 64, 34, 34]           8,256\n",
      "             Conv-61           [-1, 64, 34, 34]               0\n",
      "      BatchNorm2d-62           [-1, 64, 34, 34]             128\n",
      "             ReLU-63           [-1, 64, 34, 34]               0\n",
      "           Conv2d-64           [-1, 64, 34, 34]             128\n",
      "           Conv2d-65            [-1, 1, 34, 34]              65\n",
      "             Conv-66            [-1, 1, 34, 34]               0\n",
      "      BatchNorm2d-67            [-1, 1, 34, 34]               2\n",
      "             ReLU-68            [-1, 1, 34, 34]               0\n",
      "           Conv2d-69            [-1, 1, 34, 34]              10\n",
      "           Conv2d-70            [-1, 1, 34, 34]               2\n",
      "             Conv-71            [-1, 1, 34, 34]               0\n",
      "      BatchNorm2d-72            [-1, 1, 34, 34]               2\n",
      "             ReLU-73            [-1, 1, 34, 34]               0\n",
      "           Conv2d-74            [-1, 1, 34, 34]               2\n",
      "           Conv2d-75           [-1, 64, 34, 34]             128\n",
      "             Conv-76           [-1, 64, 34, 34]               0\n",
      "    ResidualBlock-77           [-1, 64, 34, 34]               0\n",
      "      BatchNorm2d-78           [-1, 64, 34, 34]             128\n",
      "             ReLU-79           [-1, 64, 34, 34]               0\n",
      "           Conv2d-80           [-1, 64, 17, 17]             640\n",
      "           Conv2d-81          [-1, 224, 17, 17]          14,560\n",
      "             Conv-82          [-1, 224, 17, 17]               0\n",
      "      BatchNorm2d-83          [-1, 224, 17, 17]             448\n",
      "             ReLU-84          [-1, 224, 17, 17]               0\n",
      "           Conv2d-85          [-1, 224, 17, 17]             448\n",
      "           Conv2d-86            [-1, 1, 17, 17]             225\n",
      "             Conv-87            [-1, 1, 17, 17]               0\n",
      "      BatchNorm2d-88            [-1, 1, 17, 17]               2\n",
      "             ReLU-89            [-1, 1, 17, 17]               0\n",
      "           Conv2d-90            [-1, 1, 17, 17]              10\n",
      "           Conv2d-91            [-1, 1, 17, 17]               2\n",
      "             Conv-92            [-1, 1, 17, 17]               0\n",
      "      BatchNorm2d-93            [-1, 1, 17, 17]               2\n",
      "             ReLU-94            [-1, 1, 17, 17]               0\n",
      "           Conv2d-95            [-1, 1, 17, 17]               2\n",
      "           Conv2d-96          [-1, 224, 17, 17]             448\n",
      "             Conv-97          [-1, 224, 17, 17]               0\n",
      "    ResidualBlock-98          [-1, 224, 17, 17]               0\n",
      "      BatchNorm2d-99          [-1, 224, 17, 17]             448\n",
      "            ReLU-100          [-1, 224, 17, 17]               0\n",
      "          Conv2d-101          [-1, 224, 15, 15]           2,240\n",
      "          Conv2d-102          [-1, 224, 15, 15]          50,400\n",
      "            Conv-103          [-1, 224, 15, 15]               0\n",
      "     BatchNorm2d-104          [-1, 224, 15, 15]             448\n",
      "            ReLU-105          [-1, 224, 15, 15]               0\n",
      "          Conv2d-106            [-1, 224, 8, 8]           2,240\n",
      "          Conv2d-107            [-1, 512, 8, 8]         115,200\n",
      "            Conv-108            [-1, 512, 8, 8]               0\n",
      "     BatchNorm2d-109            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-110            [-1, 512, 8, 8]               0\n",
      "          Conv2d-111            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-112            [-1, 512, 8, 8]         262,656\n",
      "            Conv-113            [-1, 512, 8, 8]               0\n",
      "     BatchNorm2d-114            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-115            [-1, 512, 8, 8]               0\n",
      "          Conv2d-116            [-1, 512, 8, 8]           5,120\n",
      "          Conv2d-117            [-1, 512, 8, 8]         262,656\n",
      "            Conv-118            [-1, 512, 8, 8]               0\n",
      "     BatchNorm2d-119            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-120            [-1, 512, 8, 8]               0\n",
      "          Conv2d-121            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-122            [-1, 512, 8, 8]         262,656\n",
      "            Conv-123            [-1, 512, 8, 8]               0\n",
      "InvertedResidualBlock-124            [-1, 512, 8, 8]               0\n",
      "     BatchNorm2d-125            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-126            [-1, 512, 8, 8]               0\n",
      "          Conv2d-127            [-1, 512, 4, 4]           5,120\n",
      "          Conv2d-128            [-1, 512, 4, 4]         262,656\n",
      "            Conv-129            [-1, 512, 4, 4]               0\n",
      "     BatchNorm2d-130            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-131            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-132            [-1, 512, 1, 1]               0\n",
      "         Dropout-133                  [-1, 512]               0\n",
      "          Linear-134                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 1,337,457\n",
      "Trainable params: 1,337,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.29\n",
      "Forward/backward pass size (MB): 91.15\n",
      "Params size (MB): 5.10\n",
      "Estimated Total Size (MB): 97.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize,dropout).to(device)\n",
    "\n",
    "summary(model, input_size=(15,150,150))\n",
    "\n",
    "# x = torch.randn(10, 15, 250, 250).to(device)\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# out = model(x)\n",
    "\n",
    "# print(out.shape)\n",
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260bdf1",
   "metadata": {},
   "source": [
    "Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8870a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fire': 0, 'non fire': 1}\n",
      "Size of the training data : 17555\n",
      "Size of the validation data : 4389\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------\n",
    "# Load the data and apply random split\n",
    "#-------------------------------------\n",
    "\n",
    "# train_path = r'../Dataset/Fire, Smoke and Non-Fire (binary)/train/'\n",
    "train_path = r'./train2/'\n",
    "mean = [0.4029, 0.3436, 0.2767]\n",
    "std = [0.2259, 0.1956, 0.1756]\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((250,250)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "\n",
    "dataset = Load_Dataset(train_path)\n",
    "\n",
    "train_size = int(0.8*len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(dataset.class_to_idx)\n",
    "print(f'Size of the training data : {len(train_data)}') \n",
    "print(f'Size of the validation data : {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d94b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# Function to calculate  mean and std\n",
    "# ------------------------------------\n",
    "\n",
    "def compute_mean_and_std(dataset):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    nb_samples = 0\n",
    "\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    for image,_ in tqdm(dataset):\n",
    "        data = to_tensor(image).to(device)\n",
    "        mean += data.mean(dim=(1,2))\n",
    "        std += data.std(dim=(1,2))\n",
    "        nb_samples += 1\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"Mean: {mean.cpu()}\")\n",
    "    print(f\"Std: {std.cpu()}\")\n",
    "\n",
    "# compute_mean_and_std(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f193b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is transformed into tensor\n",
      "torch.Size([15, 150, 150])\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Transform the train data and val data\n",
    "#--------------------------------------\n",
    "\n",
    "mean = [0.4029, 0.3436, 0.2767]\n",
    "std = [0.2259, 0.1956, 0.1756]\n",
    "\n",
    "train_dataset = Transform_Dataset(train_data, mean, std)\n",
    "val_dataset = Transform_Dataset(val_data, mean, std)\n",
    "\n",
    "print(\"Data is transformed into tensor\")\n",
    "print(next(iter(train_dataset))[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b975b69",
   "metadata": {},
   "source": [
    "Training Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473b8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize)\n",
    "                       \n",
    "\n",
    "batch_size = 32\n",
    "learning_rate =  0.0011964\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00045)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 11, 0.1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03613e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [08:35<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.2294, Train Accuracy: 91.1478,           Val Loss: 0.1353,  Val Accuracy: 96.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:02<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Train Loss: 0.1296, Train Accuracy: 95.5967,           Val Loss: 0.1051,  Val Accuracy: 96.3773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [09:58<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Train Loss: 0.1046, Train Accuracy: 96.3600,           Val Loss: 0.0860,  Val Accuracy: 97.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:02<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Train Loss: 0.0854, Train Accuracy: 96.9524,           Val Loss: 0.1161,  Val Accuracy: 95.8533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [09:54<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Train Loss: 0.0767, Train Accuracy: 97.3569,           Val Loss: 0.1198,  Val Accuracy: 96.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Train Loss: 0.0742, Train Accuracy: 97.4025,           Val Loss: 0.0673,  Val Accuracy: 98.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Train Loss: 0.0714, Train Accuracy: 97.5904,           Val Loss: 0.0841,  Val Accuracy: 97.2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [09:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Train Loss: 0.0605, Train Accuracy: 97.8923,           Val Loss: 0.0973,  Val Accuracy: 96.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Train Loss: 0.0618, Train Accuracy: 97.9037,           Val Loss: 0.0617,  Val Accuracy: 98.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [08:50<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Train Loss: 0.0580, Train Accuracy: 97.9664,           Val Loss: 0.0602,  Val Accuracy: 98.2912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Train Loss: 0.0539, Train Accuracy: 98.1999,           Val Loss: 0.0592,  Val Accuracy: 98.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Train Loss: 0.0336, Train Accuracy: 98.9120,           Val Loss: 0.0495,  Val Accuracy: 98.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Train Loss: 0.0247, Train Accuracy: 99.1911,           Val Loss: 0.0491,  Val Accuracy: 98.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Train Loss: 0.0215, Train Accuracy: 99.2652,           Val Loss: 0.0510,  Val Accuracy: 98.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:02<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Train Loss: 0.0159, Train Accuracy: 99.4816,           Val Loss: 0.0503,  Val Accuracy: 98.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Train Loss: 0.0149, Train Accuracy: 99.5044,           Val Loss: 0.0520,  Val Accuracy: 98.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Train Loss: 0.0111, Train Accuracy: 99.6069,           Val Loss: 0.0524,  Val Accuracy: 98.6102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Train Loss: 0.0108, Train Accuracy: 99.6525,           Val Loss: 0.0591,  Val Accuracy: 98.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Train Loss: 0.0090, Train Accuracy: 99.6981,           Val Loss: 0.0565,  Val Accuracy: 98.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:02<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Train Loss: 0.0066, Train Accuracy: 99.7494,           Val Loss: 0.0609,  Val Accuracy: 98.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Train Loss: 0.0066, Train Accuracy: 99.7380,           Val Loss: 0.0560,  Val Accuracy: 98.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:06<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Train Loss: 0.0065, Train Accuracy: 99.7266,           Val Loss: 0.0582,  Val Accuracy: 98.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Train Loss: 0.0054, Train Accuracy: 99.7778,           Val Loss: 0.0598,  Val Accuracy: 98.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Train Loss: 0.0041, Train Accuracy: 99.8462,           Val Loss: 0.0585,  Val Accuracy: 98.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [10:06<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.0054, Train Accuracy: 99.7778,           Val Loss: 0.0581,  Val Accuracy: 98.6557\n",
      "The best performance epoch : 20, train loss 0.0066,      and val acc 98.7924\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Training the model with tuned hyperparameters\n",
    "#----------------------------------------------\n",
    "\n",
    "num_epochs=25\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy =0.0\n",
    "    \n",
    "    for images,labels in tqdm(train_loader,leave=None):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        prediction = torch.argmax(outputs,dim =1)            \n",
    "        train_accuracy += torch.sum(prediction == labels.data)\n",
    "    \n",
    "    scheduler.step()\n",
    "            \n",
    "    # Evaluation of the model \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_accuracy =0.0\n",
    "\n",
    "    for images,labels in val_loader:\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            val_loss += loss.item()\n",
    "            prediction = torch.argmax(outputs,dim =1)\n",
    "            val_accuracy += torch.sum(prediction == labels.data)\n",
    "            \n",
    "    print(f\"Epoch {epoch +1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {100*(train_accuracy/len(train_data)):.4f},\\\n",
    "           Val Loss: {val_loss/len(val_loader):.4f},  Val Accuracy: {100*(val_accuracy/len(val_data)):.4f}\")\n",
    "    \n",
    "    if best_train_loss > train_loss and best_val_accuracy < val_accuracy:\n",
    "        best_train_loss = train_loss\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(),'EMU_FireNet_BO_BestWeighs_PV6.pth')\n",
    "\n",
    "print(f'The best performance epoch : {best_epoch}, train loss {best_train_loss/len(train_loader):.4f},\\\n",
    "      and val acc {100*best_val_accuracy/len(val_data):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1300e",
   "metadata": {},
   "source": [
    "Testing model Configuration with Large Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736bb97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize)\n",
    "\n",
    "model.load_state_dict(torch.load('EMU_FireNet_BO_BestWeighs_PV6.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e4a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    count = 0\n",
    "\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(outputs,dim =1) \n",
    "            test_accuracy += torch.sum(prediction == labels.data)\n",
    "            predictions.extend(prediction.cpu())\n",
    "            targets.extend(labels.cpu())\n",
    "            count += images.size(0)\n",
    "            \n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap= 'Blues', cbar= False, yticklabels=['fire', 'non fire'],\\\n",
    "                xticklabels=['fire', 'non fire'],square=True, center = True)\n",
    "    print(f\" test Loss: {test_loss/len(test_loader):.4f},  test Accuracy: {100*(test_accuracy/count):.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f92cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fire': 0, 'non fire': 1}\n",
      "Size of the test data : 7000\n"
     ]
    }
   ],
   "source": [
    "mean = [0.4029, 0.3436, 0.2767]\n",
    "std = [0.2259, 0.1956, 0.1756]\n",
    "\n",
    "test_path = r'./test/'\n",
    "test_data = Load_Dataset(test_path)\n",
    "test_dataset = Transform_Dataset(test_data, mean, std)\n",
    "\n",
    "print(test_data.class_to_idx)\n",
    "print(f'Size of the test data : {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9191369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [02:52<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Loss: 0.0251,  test Accuracy: 99.4143\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, 16, None)\n",
    "model.to(device)\n",
    "model_predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2b391",
   "metadata": {},
   "source": [
    "Test with corsican dataset 1-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95db6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fire': 0}\n",
      "Size of the test data : 500\n"
     ]
    }
   ],
   "source": [
    "mean = [0.4009, 0.3412, 0.2750]\n",
    "std = [0.2247, 0.1942, 0.1743]\n",
    "\n",
    "corsican_path = r'c:/Users/Sc/Desktop/CorsicanDataset/'\n",
    "corsican_data = Load_Dataset(corsican_path)\n",
    "corsican_dataset = Transform_Dataset(corsican_data, mean, std)\n",
    "\n",
    "print(corsican_data.class_to_idx)\n",
    "print(f'Size of the test data : {len(corsican_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72040049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize)\n",
    "                       \n",
    "model.load_state_dict(torch.load('EMU_FireNet_BO_BestWeighs_PV6.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2c88e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    count = 0\n",
    "\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(outputs,dim =1) \n",
    "            test_accuracy += torch.sum(prediction == labels.data)\n",
    "            predictions.extend(prediction.cpu())\n",
    "            targets.extend(labels.cpu())\n",
    "            count += images.size(0)\n",
    "            \n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap= 'Blues', cbar= False, yticklabels=['fire', 'non fire'],\\\n",
    "                xticklabels=['fire', 'non fire'],square=True, center = True)\n",
    "    print(f\" test Loss: {test_loss/len(test_loader):.4f},  test Accuracy: {100*(test_accuracy/count):.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d561a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:52<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Loss: 0.1444,  test Accuracy: 94.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corsicandata_loader = DataLoader(corsican_dataset, 32, None)\n",
    "model.to(device)\n",
    "\n",
    "model_predict(corsicandata_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8e86c",
   "metadata": {},
   "source": [
    "Test using DeepFire Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2984bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0, 'N': 1}\n",
      "Size of the test data : 1900\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "# Import the data, preprocess and random split\n",
    "#---------------------------------------------\n",
    "mean = [0.4009, 0.3412, 0.2750]\n",
    "std = [0.2247, 0.1942, 0.1743]\n",
    "\n",
    "deepfire_path = r'c:/Users/Sc/Desktop/Programs_VisualStudioCode/Dataset2/'\n",
    "deepfire_data = Load_Dataset(deepfire_path)\n",
    "deepfire_dataset = Transform_Dataset(deepfire_data, mean, std)\n",
    "\n",
    "print(deepfire_data.class_to_idx)\n",
    "print(f'Size of the test data : {len(deepfire_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14c9482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize)\n",
    "                       \n",
    "model.load_state_dict(torch.load('EMU_FireNet_BO_BestWeighs_PV6.pth'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520ccd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    count = 0\n",
    "\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(outputs,dim =1) \n",
    "            test_accuracy += torch.sum(prediction == labels.data)\n",
    "            predictions.extend(prediction.cpu())\n",
    "            targets.extend(labels.cpu())\n",
    "            count += images.size(0)\n",
    "            \n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap= 'Blues', cbar= False, yticklabels=['fire', 'non fire'],\\\n",
    "                xticklabels=['fire', 'non fire'],square=True, center = True)\n",
    "    print(f\" test Loss: {test_loss/len(test_loader):.4f},  test Accuracy: {100*(test_accuracy/count):.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ed2480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:24<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Loss: 0.0038,  test Accuracy: 99.9474\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "deepfire_loader = DataLoader(deepfire_dataset, batch_size, None)\n",
    "model.to(device)\n",
    "\n",
    "model_predict(deepfire_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71ac8c",
   "metadata": {},
   "source": [
    "Test using EMUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aebe99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0, 'N': 1}\n",
      "Size of the test data : 3606\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "# Import the data, preprocess and random split\n",
    "#---------------------------------------------\n",
    "mean = [0.4009, 0.3412, 0.2750]\n",
    "std = [0.2247, 0.1942, 0.1743]\n",
    "\n",
    "emudataset_path = r'c:/Users/Sc/Desktop/EMUDataset/'\n",
    "emu_data = Load_Dataset(emudataset_path)\n",
    "emu_dataset = Transform_Dataset(emu_data, mean, std)\n",
    "\n",
    "print(emu_data.class_to_idx)\n",
    "print(f'Size of the test data : {len(emu_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0384f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth1 = 32\n",
    "depth2 = 1\n",
    "depth3 = 9\n",
    "depth4 = 64\n",
    "depth5 = 64\n",
    "depth6 = 128\n",
    "depth7 = 64\n",
    "depth8 = 224\n",
    "depth9 = 512\n",
    "depth10 = 512\n",
    "hidden_depth = 128\n",
    "hidden_depth2 = 512\n",
    "kernel1 = 7\n",
    "kernel2 = 3\n",
    "kernel3 = 3\n",
    "stride = 2\n",
    "padding1 = 5\n",
    "padding2 = 0\n",
    "avgsize = 1\n",
    "dropout = 0.2\n",
    "\n",
    "model = EMU_FireNet(depth1, depth2, depth3, depth4, depth5, depth6,\n",
    "                    depth7, depth8, depth9, depth10, hidden_depth, hidden_depth2,\n",
    "                    kernel1, kernel2, kernel3, stride, padding1, padding2, avgsize)\n",
    "                       \n",
    "model.load_state_dict(torch.load('EMU_FireNet_BO_BestWeighs_PV6.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c4744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    count = 0\n",
    "\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(outputs,dim =1) \n",
    "            test_accuracy += torch.sum(prediction == labels.data)\n",
    "            predictions.extend(prediction.cpu())\n",
    "            targets.extend(labels.cpu())\n",
    "            count += images.size(0)\n",
    "            \n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap= 'Blues', cbar= False, yticklabels=['fire', 'non fire'],\\\n",
    "                xticklabels=['fire', 'non fire'],square=True, center = True)\n",
    "    print(f\" test Loss: {test_loss/len(test_loader):.4f},  test Accuracy: {100*(test_accuracy/count):.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "890f72b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [09:17<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Loss: 0.1348,  test Accuracy: 96.8663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "emudata_loader = DataLoader(emu_dataset, batch_size, None)\n",
    "model.to(device)\n",
    "\n",
    "model_predict(emudata_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9abcc786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 75, 75]             150\n",
      "            Conv2d-2           [-1, 16, 75, 75]              64\n",
      "              Conv-3           [-1, 16, 75, 75]               0\n",
      "       BatchNorm2d-4           [-1, 16, 75, 75]              32\n",
      "             Block-5           [-1, 16, 75, 75]               0\n",
      "            Conv2d-6            [-1, 3, 75, 75]             150\n",
      "            Conv2d-7            [-1, 2, 75, 75]               8\n",
      "              Conv-8            [-1, 2, 75, 75]               0\n",
      "       BatchNorm2d-9            [-1, 2, 75, 75]               4\n",
      "            Block-10            [-1, 2, 75, 75]               0\n",
      "        AvgPool2d-11            [-1, 9, 75, 75]               0\n",
      "           Conv2d-12           [-1, 27, 71, 71]             702\n",
      "           Conv2d-13           [-1, 64, 71, 71]           1,792\n",
      "             Conv-14           [-1, 64, 71, 71]               0\n",
      "      BatchNorm2d-15           [-1, 64, 71, 71]             128\n",
      "             ReLU-16           [-1, 64, 71, 71]               0\n",
      "           Conv2d-17           [-1, 64, 67, 67]           1,664\n",
      "           Conv2d-18           [-1, 64, 67, 67]           4,160\n",
      "             Conv-19           [-1, 64, 67, 67]               0\n",
      "      BatchNorm2d-20           [-1, 64, 67, 67]             128\n",
      "             ReLU-21           [-1, 64, 67, 67]               0\n",
      "           Conv2d-22           [-1, 64, 67, 67]             128\n",
      "           Conv2d-23            [-1, 1, 67, 67]              65\n",
      "             Conv-24            [-1, 1, 67, 67]               0\n",
      "      BatchNorm2d-25            [-1, 1, 67, 67]               2\n",
      "             ReLU-26            [-1, 1, 67, 67]               0\n",
      "           Conv2d-27            [-1, 1, 67, 67]              26\n",
      "           Conv2d-28            [-1, 1, 67, 67]               2\n",
      "             Conv-29            [-1, 1, 67, 67]               0\n",
      "      BatchNorm2d-30            [-1, 1, 67, 67]               2\n",
      "             ReLU-31            [-1, 1, 67, 67]               0\n",
      "           Conv2d-32            [-1, 1, 67, 67]               2\n",
      "           Conv2d-33           [-1, 64, 67, 67]             128\n",
      "             Conv-34           [-1, 64, 67, 67]               0\n",
      "    ResidualBlock-35           [-1, 64, 67, 67]               0\n",
      "      BatchNorm2d-36           [-1, 64, 67, 67]             128\n",
      "             ReLU-37           [-1, 64, 67, 67]               0\n",
      "           Conv2d-38           [-1, 64, 34, 34]             640\n",
      "           Conv2d-39           [-1, 32, 34, 34]           2,080\n",
      "             Conv-40           [-1, 32, 34, 34]               0\n",
      "      BatchNorm2d-41           [-1, 32, 34, 34]              64\n",
      "             ReLU-42           [-1, 32, 34, 34]               0\n",
      "           Conv2d-43           [-1, 32, 34, 34]              64\n",
      "           Conv2d-44          [-1, 128, 34, 34]           4,224\n",
      "             Conv-45          [-1, 128, 34, 34]               0\n",
      "      BatchNorm2d-46          [-1, 128, 34, 34]             256\n",
      "             ReLU-47          [-1, 128, 34, 34]               0\n",
      "           Conv2d-48          [-1, 128, 34, 34]           1,280\n",
      "           Conv2d-49          [-1, 128, 34, 34]          16,512\n",
      "             Conv-50          [-1, 128, 34, 34]               0\n",
      "      BatchNorm2d-51          [-1, 128, 34, 34]             256\n",
      "             ReLU-52          [-1, 128, 34, 34]               0\n",
      "           Conv2d-53          [-1, 128, 34, 34]             256\n",
      "           Conv2d-54           [-1, 32, 34, 34]           4,128\n",
      "             Conv-55           [-1, 32, 34, 34]               0\n",
      "InvertedResidualBlock-56           [-1, 32, 34, 34]               0\n",
      "      BatchNorm2d-57           [-1, 32, 34, 34]              64\n",
      "             ReLU-58           [-1, 32, 34, 34]               0\n",
      "           Conv2d-59           [-1, 32, 32, 32]             320\n",
      "           Conv2d-60          [-1, 128, 32, 32]           4,224\n",
      "             Conv-61          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-62          [-1, 128, 32, 32]             256\n",
      "             ReLU-63          [-1, 128, 32, 32]               0\n",
      "           Conv2d-64          [-1, 128, 32, 32]             256\n",
      "           Conv2d-65            [-1, 1, 32, 32]             129\n",
      "             Conv-66            [-1, 1, 32, 32]               0\n",
      "      BatchNorm2d-67            [-1, 1, 32, 32]               2\n",
      "             ReLU-68            [-1, 1, 32, 32]               0\n",
      "           Conv2d-69            [-1, 1, 32, 32]              10\n",
      "           Conv2d-70            [-1, 1, 32, 32]               2\n",
      "             Conv-71            [-1, 1, 32, 32]               0\n",
      "      BatchNorm2d-72            [-1, 1, 32, 32]               2\n",
      "             ReLU-73            [-1, 1, 32, 32]               0\n",
      "           Conv2d-74            [-1, 1, 32, 32]               2\n",
      "           Conv2d-75          [-1, 128, 32, 32]             256\n",
      "             Conv-76          [-1, 128, 32, 32]               0\n",
      "    ResidualBlock-77          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-78          [-1, 128, 32, 32]             256\n",
      "             ReLU-79          [-1, 128, 32, 32]               0\n",
      "           Conv2d-80          [-1, 128, 16, 16]           1,280\n",
      "           Conv2d-81          [-1, 512, 16, 16]          66,048\n",
      "             Conv-82          [-1, 512, 16, 16]               0\n",
      "      BatchNorm2d-83          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-84          [-1, 512, 16, 16]               0\n",
      "           Conv2d-85          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-86            [-1, 1, 16, 16]             513\n",
      "             Conv-87            [-1, 1, 16, 16]               0\n",
      "      BatchNorm2d-88            [-1, 1, 16, 16]               2\n",
      "             ReLU-89            [-1, 1, 16, 16]               0\n",
      "           Conv2d-90            [-1, 1, 16, 16]              10\n",
      "           Conv2d-91            [-1, 1, 16, 16]               2\n",
      "             Conv-92            [-1, 1, 16, 16]               0\n",
      "      BatchNorm2d-93            [-1, 1, 16, 16]               2\n",
      "             ReLU-94            [-1, 1, 16, 16]               0\n",
      "           Conv2d-95            [-1, 1, 16, 16]               2\n",
      "           Conv2d-96          [-1, 512, 16, 16]           1,024\n",
      "             Conv-97          [-1, 512, 16, 16]               0\n",
      "    ResidualBlock-98          [-1, 512, 16, 16]               0\n",
      "      BatchNorm2d-99          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-100          [-1, 512, 16, 16]               0\n",
      "          Conv2d-101          [-1, 512, 14, 14]           5,120\n",
      "          Conv2d-102          [-1, 512, 14, 14]         262,656\n",
      "            Conv-103          [-1, 512, 14, 14]               0\n",
      "     BatchNorm2d-104          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-105          [-1, 512, 14, 14]               0\n",
      "          Conv2d-106            [-1, 512, 7, 7]           5,120\n",
      "          Conv2d-107            [-1, 512, 7, 7]         262,656\n",
      "            Conv-108            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-109            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "          Conv2d-111            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-112            [-1, 512, 7, 7]         262,656\n",
      "            Conv-113            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]           5,120\n",
      "          Conv2d-117            [-1, 512, 7, 7]         262,656\n",
      "            Conv-118            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-119            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-120            [-1, 512, 7, 7]               0\n",
      "          Conv2d-121            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-122            [-1, 512, 7, 7]         262,656\n",
      "            Conv-123            [-1, 512, 7, 7]               0\n",
      "InvertedResidualBlock-124            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-126            [-1, 512, 7, 7]               0\n",
      "          Conv2d-127            [-1, 512, 4, 4]          13,312\n",
      "          Conv2d-128            [-1, 256, 4, 4]         131,328\n",
      "            Conv-129            [-1, 256, 4, 4]               0\n",
      "     BatchNorm2d-130            [-1, 256, 4, 4]             512\n",
      "            ReLU-131            [-1, 256, 4, 4]               0\n",
      "AdaptiveAvgPool2d-132            [-1, 256, 2, 2]               0\n",
      "         Dropout-133                 [-1, 1024]               0\n",
      "          Linear-134                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 1,599,969\n",
      "Trainable params: 1,599,969\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.29\n",
      "Forward/backward pass size (MB): 82.40\n",
      "Params size (MB): 6.10\n",
      "Estimated Total Size (MB): 89.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(15,150,150))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
